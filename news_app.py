import streamlit as st
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re

# --------------------- ë‹¤í¬ëª¨ë“œ í…Œë§ˆ ì„¤ì • ---------------------
st.set_page_config(page_title="ë””ì‹œì¸ì‚¬ì´ë“œ ê°œë…ê¸€ ìˆ˜ì§‘ê¸°", layout="wide")
st.markdown("""
    <style>
    html, body, [class*="css"]  {
        background-color: #1e1e1e !important;
        color: #ffffff !important;
    }
    .stApp {
        background-color: #1e1e1e;
        color: #ffffff;
    }
    .block-container {
        background-color: #1e1e1e;
    }
    .stSidebar, .st-bb, .st-bx, .st-c3, .st-dc, .st-em, .st-bo, .st-bq {
        background-color: #2a2a2a !important;
        color: #ffffff !important;
    }
    .stButton>button {
        background-color: #444444;
        color: #ffffff;
    }
    a {
        color: #ffffff !important;
        text-decoration: underline;
    }
    .post-date {
        font-size: 0.8em;
        color: #aaaaaa;
        margin-left: 10px;
    }
    </style>
""", unsafe_allow_html=True)

# --------------------- ì¸ê¸° ê°¤ëŸ¬ë¦¬ ëª©ë¡ ---------------------
gallery_list = {
    "ì£¼ì‹ ê°¤ëŸ¬ë¦¬": "stock",
    "í•´ì™¸ì—°ì˜ˆ ê°¤ëŸ¬ë¦¬": "foreign",
    "í”„ë¡œê·¸ë¨ ê°¤ëŸ¬ë¦¬": "programming",
    "AI ê·¸ë¦¼ ê°¤ëŸ¬ë¦¬": "ai",
    "ì—°ì•  ê°¤ëŸ¬ë¦¬": "love",
    "íˆì–´ë¡œë¬¼ ê°¤ëŸ¬ë¦¬": "superhero",
    "ì •ì¹˜ ê°¤ëŸ¬ë¦¬": "politics",
    "ì•¼êµ¬ ê°¤ëŸ¬ë¦¬": "baseball_new9",
    "ê²Œì„ ê°¤ëŸ¬ë¦¬": "game",
    "ì´ì„¸ê³„ ê°¤ëŸ¬ë¦¬": "isekaigal"
}

st.title("ğŸ”¥ ë””ì‹œì¸ì‚¬ì´ë“œ ì¸ê¸° ê°¤ëŸ¬ë¦¬ ê°œë…ê¸€ ìˆ˜ì§‘ê¸°")
st.markdown(f"#### ğŸ“… ì˜¤ëŠ˜ ë‚ ì§œ: {datetime.now().strftime('%Y-%m-%d')}")
st.markdown("[ğŸ‘‰ ë””ì‹œì¸ì‚¬ì´ë“œ ë©”ì¸ìœ¼ë¡œ ê°€ê¸°](https://www.dcinside.com)")

# --------------------- ê°œë…ê¸€ ìˆ˜ì§‘ í•¨ìˆ˜ ---------------------
def fetch_gall_contents(gall_id):
    url = f"https://gall.dcinside.com/mgallery/board/lists/?id={gall_id}&exception_mode=recommend&sort_type=N"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, "html.parser")
        rows = soup.select("tr.ub-content")
        result = []
        for row in rows:
            a_tag = row.select_one("td.gall_tit.ub-word > a")
            date_tag = row.select_one("td.gall_date")
            if not a_tag or not date_tag:
                continue
            title = a_tag.get_text(strip=True)
            href = a_tag.get("href", "")
            date = date_tag.get("title") or date_tag.get_text(strip=True)
            if re.fullmatch(r"\[\d+\]", title):
                continue
            if title and "/board/view/" in href:
                full_url = "https://gall.dcinside.com" + href
                result.append((title, full_url, date))
        return result
    except:
        pass
    return []

# --------------------- ê°¤ëŸ¬ë¦¬ë³„ ê°œë…ê¸€ ì¶œë ¥ ---------------------
for name, gall_id in gallery_list.items():
    with st.expander(f"ğŸ“Œ {name} ({gall_id}) ê°œë…ê¸€ ë³´ê¸°"):
        try:
            posts = fetch_gall_contents(gall_id)
            if posts:
                for title, link, date in posts:
                    st.markdown(f"- [{title}]({link}) <span class='post-date'>({date})</span>", unsafe_allow_html=True)
            else:
                st.write("(í‘œì‹œí•  ê°œë…ê¸€ì´ ì—†ìŠµë‹ˆë‹¤)")
        except:
            st.write("âŒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")